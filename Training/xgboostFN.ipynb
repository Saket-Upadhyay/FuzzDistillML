{
 "cells": [
  {
   "cell_type": "code",
   "id": "c8dd9aed-5b00-439e-b3cd-62c8baa8838b",
   "metadata": {},
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "from includes.constants import FN_UNIMPORTANT_FEATURES, FN_CPP_MEMORY_FEATURES, FN_TARGET_FEATURE, FN_EXPLICIT_EXCLUDE_FEATURES\n",
    "from includes.helpers import get_function_train_test_set\n",
    "from includes.constants import GLOBAL_RANDOM_STATE"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c30b9b19-92a8-43cc-ad6f-4754b0774ecf",
   "metadata": {},
   "source": [
    "X_train, X_test, y_train, y_test = get_function_train_test_set()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e584b5e8-e4e5-4f77-96e3-d855c2a4f737",
   "metadata": {},
   "source": [
    "# Step 4: Feature scaling (if needed)\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled = X_train\n",
    "X_test_scaled = X_test"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "494fd15f-1c74-4786-a74e-698de632f890",
   "metadata": {},
   "source": [
    "# Best Cross-validation Accuracy: 0.6840\n",
    "model = xgb.XGBClassifier(\n",
    "  objective='binary:logistic',\n",
    "  eval_metric='logloss',\n",
    "  random_state=GLOBAL_RANDOM_STATE,\n",
    "  colsample_bytree=0.8,\n",
    "  learning_rate=0.05,\n",
    "  max_depth=10,\n",
    "  n_estimators=400,\n",
    "  subsample=0.8\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "  X_train_scaled, y_train\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6092dfd6-51a2-4f06-9d04-48cbccbb4892",
   "metadata": {},
   "source": [
    "# Predict class labels\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Predict probabilities (useful for AUC-ROC)\n",
    "y_proba = model.predict_proba(X_test_scaled)[:, 1]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4b2b7415-5d59-4079-b79e-c0d5b9615474",
   "metadata": {},
   "source": [
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# AUC-ROC\n",
    "auc_roc = roc_auc_score(y_test, y_proba)\n",
    "print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3ab210c8-1e54-40b9-a68a-fc2a80d0ee77",
   "metadata": {},
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f'AUC = {auc_roc:.4f}')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label=\"Random Guess\")\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "201022dc-b75d-4a6c-ab9b-6a674a7717e8",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9c2e98e4-bf98-4042-ad25-f3f201a69ab9",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "33b6fac6-d274-4582-aabc-212b7fb8394a",
   "metadata": {},
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# Compute precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "\n",
    "# Plot precision-recall curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, label='Precision-Recall Curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f487a5c2-0ee9-42d0-9d12-6b53c4e001a2",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get feature importance from the model\n",
    "importance = model.feature_importances_\n",
    "\n",
    "# Sort features by importance\n",
    "sorted_idx = np.argsort(importance)[::-1]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(range(len(importance)), importance[sorted_idx], align='center',color='blue')\n",
    "plt.yticks(range(len(importance)), [X_train.columns[i] for i in sorted_idx])\n",
    "plt.title('Feature Importance (XGBoost)')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.tight_layout()\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to show the most important feature on top\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f7c9ba5c-2bab-4c38-94e7-0fea2e447a2b",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    model, X_train_scaled, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Calculate mean and std of scores\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# Plot learning curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_sizes, train_mean, label='Training Accuracy', color='blue')\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color='blue', alpha=0.2)\n",
    "plt.plot(train_sizes, test_mean, label='Validation Accuracy', color='green')\n",
    "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color='green', alpha=0.2)\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Learning Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "145b5e54-9837-432c-aa4f-11e74bc6650f",
   "metadata": {},
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "# Compute calibration curve\n",
    "prob_true, prob_pred = calibration_curve(y_test, y_proba, n_bins=10)\n",
    "\n",
    "# Plot calibration curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(prob_pred, prob_true, marker='o', label='Calibration Curve')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Perfect Calibration')\n",
    "plt.xlabel('Mean Predicted Probability')\n",
    "plt.ylabel('Fraction of Positives')\n",
    "plt.title('Calibration Curve')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f9088ec2-e4dd-4748-b870-8813e2d5fa62",
   "metadata": {},
   "source": [
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(y_proba[y_test == 0], bins=50, alpha=0.6, label='Class 0', color='blue')\n",
    "plt.hist(y_proba[y_test == 1], bins=50, alpha=0.6, label='Class 1', color='red')\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Predicted Probabilities')\n",
    "plt.legend(loc='upper center')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "95701713-ab0b-4b7a-973d-c98d60b0766d",
   "metadata": {},
   "source": [
    "residuals = y_proba - y_test\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(range(len(residuals)), residuals, alpha=0.6, color='purple')\n",
    "plt.axhline(0, color='black', linestyle='--')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#HYPER PARAM OPT XGB\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'n_estimators': [100, 200, 400],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb.XGBClassifier(objective='binary:logistic', random_state=GLOBAL_RANDOM_STATE),\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',  # Or use other metrics like 'roc_auc'\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=1,\n",
    "    n_jobs=-1  # Parallel processing\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n"
   ],
   "id": "8f4d2020-70de-4d50-898c-d82e09910cc2",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
